<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>Kernel-3.10.0-957.el7_cpusets | oosTech.com</title>
  <meta name="description" content="CPUSETS             -------  Copyright (C) 2004 BULL SA.Written by &amp;#x53;&amp;#105;&amp;#x6d;&amp;#111;&amp;#110;&amp;#x2e;&amp;#68;&amp;#x65;&amp;#x72;&amp;#x72;&amp;#64;&amp;#98;&amp;#x75;&amp;#x6c;&amp;#108;&amp;#x2e;&amp;#110;&amp;#101;&amp;#x74; Portions">
<meta property="og:type" content="article">
<meta property="og:title" content="Kernel-3.10.0-957.el7_cpusets">
<meta property="og:url" content="http://www.oostech.com/2021/03/13/Kernel-3.10.0-957.el7_cpusets/index.html">
<meta property="og:site_name" content="oosTech">
<meta property="og:description" content="CPUSETS             -------  Copyright (C) 2004 BULL SA.Written by &amp;#x53;&amp;#105;&amp;#x6d;&amp;#111;&amp;#110;&amp;#x2e;&amp;#68;&amp;#x65;&amp;#x72;&amp;#x72;&amp;#64;&amp;#98;&amp;#x75;&amp;#x6c;&amp;#108;&amp;#x2e;&amp;#110;&amp;#101;&amp;#x74; Portions">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-03-12T16:00:00.000Z">
<meta property="article:modified_time" content="2021-03-12T16:00:00.000Z">
<meta property="article:author" content="Sam Lee">
<meta name="twitter:card" content="summary">
  <!-- Canonical links -->
  <link rel="canonical" href="http://www.oostech.com/2021/03/13/Kernel-3.10.0-957.el7_cpusets/index.html">
  
    <link rel="alternate" href="/atom.xml" title="oosTech" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
  
  
<meta name="generator" content="Hexo 5.4.0"></head>


<body class="main-center theme-black" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="" target="_blank">
          <img src="/images/avatar.png" width="400" height="400">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">oosTech by Sam Lee</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md"></h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Shenzhen, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="站内搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav menu-highlight">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">站点首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档文档</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">文档分类</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-links">
          <a href="/links">
            
            <i class="icon icon-friendship"></i>
            
            <span class="menu-title">常用链接</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-repository">
          <a href="/repository">
            
            <i class="icon icon-project"></i>
            
            <span class="menu-title">共享白板</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="http://google.com/" target="_blank" title="Google" data-toggle=tooltip data-placement=top><i class="icon icon-google"></i></a></li>
        
        <li><a href="https://twitter.com/" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告牌</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p> 欢迎来到oosTech ，我是一个Linux 拥趸：D。 目前正在用的Linux 版本是 Red Hat Enterprise Linux release 8.3 </p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">文档分类</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Kernel-3-10-0-957-el7-%E5%86%85%E6%A0%B8%E6%96%87%E6%A1%A3/">Kernel_3.10.0-957.el7_内核文档</a><span class="category-list-count">1658</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kernel-4-18-0-80-el8-%E5%86%85%E6%A0%B8%E6%96%87%E6%A1%A3/">Kernel_4.18.0-80.el8_内核文档</a><span class="category-list-count">3937</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Kernel-3-10-0-957-el7-%E5%86%85%E6%A0%B8%E6%96%87%E6%A1%A3/">Kernel_3.10.0-957.el7_内核文档</a>
              </p>
              <p class="item-title">
                <a href="/2021/03/13/Kernel-3.10.0-957.el7_mpc5200/" class="title">Kernel-3.10.0-957.el7_mpc5200</a>
              </p>
              <p class="item-date">
                <time datetime="2021-03-12T16:00:00.000Z" itemprop="datePublished">2021-03-13</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Kernel-3-10-0-957-el7-%E5%86%85%E6%A0%B8%E6%96%87%E6%A1%A3/">Kernel_3.10.0-957.el7_内核文档</a>
              </p>
              <p class="item-title">
                <a href="/2021/03/13/Kernel-3.10.0-957.el7_3270/" class="title">Kernel-3.10.0-957.el7_3270</a>
              </p>
              <p class="item-date">
                <time datetime="2021-03-12T16:00:00.000Z" itemprop="datePublished">2021-03-13</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Kernel-3-10-0-957-el7-%E5%86%85%E6%A0%B8%E6%96%87%E6%A1%A3/">Kernel_3.10.0-957.el7_内核文档</a>
              </p>
              <p class="item-title">
                <a href="/2021/03/13/Kernel-3.10.0-957.el7_4CCs/" class="title">Kernel-3.10.0-957.el7_4CCs</a>
              </p>
              <p class="item-date">
                <time datetime="2021-03-12T16:00:00.000Z" itemprop="datePublished">2021-03-13</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Kernel-3-10-0-957-el7-%E5%86%85%E6%A0%B8%E6%96%87%E6%A1%A3/">Kernel_3.10.0-957.el7_内核文档</a>
              </p>
              <p class="item-title">
                <a href="/2021/03/13/Kernel-3.10.0-957.el7_53c700/" class="title">Kernel-3.10.0-957.el7_53c700</a>
              </p>
              <p class="item-date">
                <time datetime="2021-03-12T16:00:00.000Z" itemprop="datePublished">2021-03-13</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Kernel-3-10-0-957-el7-%E5%86%85%E6%A0%B8%E6%96%87%E6%A1%A3/">Kernel_3.10.0-957.el7_内核文档</a>
              </p>
              <p class="item-title">
                <a href="/2021/03/13/Kernel-3.10.0-957.el7_6pack/" class="title">Kernel-3.10.0-957.el7_6pack</a>
              </p>
              <p class="item-date">
                <time datetime="2021-03-12T16:00:00.000Z" itemprop="datePublished">2021-03-13</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
<aside class="sidebar sidebar-toc collapse" id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    <nav id="toc" class="article-toc">
      <h3 class="toc-title">文章目录</h3>
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#CONTENTS"><span class="toc-number">1.</span> <span class="toc-text">CONTENTS:</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Cpusets"><span class="toc-number">2.</span> <span class="toc-text">Cpusets</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-What-are-cpusets"><span class="toc-number">2.1.</span> <span class="toc-text">1.1 What are cpusets ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-Why-are-cpusets-needed"><span class="toc-number">2.2.</span> <span class="toc-text">1.2 Why are cpusets needed ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-How-are-cpusets-implemented"><span class="toc-number">2.3.</span> <span class="toc-text">1.3 How are cpusets implemented ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-What-are-exclusive-cpusets"><span class="toc-number">2.4.</span> <span class="toc-text">1.4 What are exclusive cpusets ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-What-is-memory-pressure"><span class="toc-number">2.5.</span> <span class="toc-text">1.5 What is memory_pressure ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-6-What-is-memory-spread"><span class="toc-number">2.6.</span> <span class="toc-text">1.6 What is memory spread ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-7-What-is-sched-load-balance"><span class="toc-number">2.7.</span> <span class="toc-text">1.7 What is sched_load_balance ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-7-1-sched-load-balance-implementation-details"><span class="toc-number">2.8.</span> <span class="toc-text">1.7.1 sched_load_balance implementation details.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-8-What-is-sched-relax-domain-level"><span class="toc-number">2.9.</span> <span class="toc-text">1.8 What is sched_relax_domain_level ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-9-How-do-I-use-cpusets"><span class="toc-number">2.10.</span> <span class="toc-text">1.9 How do I use cpusets ?</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#The-subshell-%E2%80%98sh%E2%80%99-is-now-running-in-cpuset-Charlie"><span class="toc-number">3.</span> <span class="toc-text">The subshell ‘sh’ is now running in cpuset Charlie</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#The-next-line-should-display-%E2%80%98-Charlie%E2%80%99"><span class="toc-number">4.</span> <span class="toc-text">The next line should display ‘&#x2F;Charlie’</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Usage-Examples-and-Syntax"><span class="toc-number">5.</span> <span class="toc-text">Usage Examples and Syntax</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-Basic-Usage"><span class="toc-number">5.1.</span> <span class="toc-text">2.1 Basic Usage</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#mount-t-cgroup-o-cpuset-cpuset-sys-fs-cgroup-cpuset"><span class="toc-number">6.</span> <span class="toc-text">mount -t cgroup -o cpuset cpuset &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpuset</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#cd-sys-fs-cgroup-cpuset"><span class="toc-number">7.</span> <span class="toc-text">cd &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpuset</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#mkdir-my-cpuset"><span class="toc-number">8.</span> <span class="toc-text">mkdir my_cpuset</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#cd-my-cpuset"><span class="toc-number">9.</span> <span class="toc-text">cd my_cpuset</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ls"><span class="toc-number">10.</span> <span class="toc-text">ls</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-1-gt-cpuset-cpu-exclusive"><span class="toc-number">11.</span> <span class="toc-text">&#x2F;bin&#x2F;echo 1 &gt; cpuset.cpu_exclusive</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-0-7-gt-cpuset-cpus"><span class="toc-number">12.</span> <span class="toc-text">&#x2F;bin&#x2F;echo 0-7 &gt; cpuset.cpus</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-0-7-gt-cpuset-mems"><span class="toc-number">13.</span> <span class="toc-text">&#x2F;bin&#x2F;echo 0-7 &gt; cpuset.mems</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-gt-tasks"><span class="toc-number">14.</span> <span class="toc-text">&#x2F;bin&#x2F;echo $$ &gt; tasks</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#mkdir-my-sub-cs"><span class="toc-number">15.</span> <span class="toc-text">mkdir my_sub_cs</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#rmdir-my-sub-cs"><span class="toc-number">16.</span> <span class="toc-text">rmdir my_sub_cs</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-Adding-removing-cpus"><span class="toc-number">16.1.</span> <span class="toc-text">2.2 Adding&#x2F;removing cpus</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-1-4-gt-cpuset-cpus-gt-set-cpus-list-to-cpus-1-2-3-4"><span class="toc-number">17.</span> <span class="toc-text">&#x2F;bin&#x2F;echo 1-4 &gt; cpuset.cpus        -&gt; set cpus list to cpus 1,2,3,4</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-1-2-3-4-gt-cpuset-cpus-gt-set-cpus-list-to-cpus-1-2-3-4"><span class="toc-number">18.</span> <span class="toc-text">&#x2F;bin&#x2F;echo 1,2,3,4 &gt; cpuset.cpus    -&gt; set cpus list to cpus 1,2,3,4</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-1-4-6-gt-cpuset-cpus-gt-set-cpus-list-to-cpus-1-2-3-4-6"><span class="toc-number">19.</span> <span class="toc-text">&#x2F;bin&#x2F;echo 1-4,6 &gt; cpuset.cpus    -&gt; set cpus list to cpus 1,2,3,4,6</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-%E2%80%9C%E2%80%9D-gt-cpuset-cpus-gt-clear-cpus-list"><span class="toc-number">20.</span> <span class="toc-text">&#x2F;bin&#x2F;echo “” &gt; cpuset.cpus        -&gt; clear cpus list</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-Setting-flags"><span class="toc-number">20.1.</span> <span class="toc-text">2.3 Setting flags</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-1-gt-cpuset-cpu-exclusive-gt-set-flag-%E2%80%98cpuset-cpu-exclusive%E2%80%99"><span class="toc-number">21.</span> <span class="toc-text">&#x2F;bin&#x2F;echo 1 &gt; cpuset.cpu_exclusive     -&gt; set flag ‘cpuset.cpu_exclusive’</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-0-gt-cpuset-cpu-exclusive-gt-unset-flag-%E2%80%98cpuset-cpu-exclusive%E2%80%99"><span class="toc-number">22.</span> <span class="toc-text">&#x2F;bin&#x2F;echo 0 &gt; cpuset.cpu_exclusive     -&gt; unset flag ‘cpuset.cpu_exclusive’</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-Attaching-processes"><span class="toc-number">22.1.</span> <span class="toc-text">2.4 Attaching processes</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-PID-gt-tasks"><span class="toc-number">23.</span> <span class="toc-text">&#x2F;bin&#x2F;echo PID &gt; tasks</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-PID1-gt-tasks"><span class="toc-number">24.</span> <span class="toc-text">&#x2F;bin&#x2F;echo PID1 &gt; tasks</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-PID2-gt-tasks"><span class="toc-number">25.</span> <span class="toc-text">&#x2F;bin&#x2F;echo PID2 &gt; tasks</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#bin-echo-PIDn-gt-tasks"><span class="toc-number">26.</span> <span class="toc-text">&#x2F;bin&#x2F;echo PIDn &gt; tasks</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Questions"><span class="toc-number">27.</span> <span class="toc-text">Questions</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Contact"><span class="toc-number">28.</span> <span class="toc-text">Contact</span></a></li></ol>
    </nav>
  </div>
</aside>

<main class="main" role="main">
  <div class="content">
  <article id="post-Kernel-3.10.0-957.el7_cpusets" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      Kernel-3.10.0-957.el7_cpusets
    </h1>
  

      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2021/03/13/Kernel-3.10.0-957.el7_cpusets/" class="article-date">
	 published: <time datetime="2021-03-12T16:00:00.000Z" itemprop="datePublished">2021-03-13</time>
	</a>
</span>

        
	<a href="/2021/03/13/Kernel-3.10.0-957.el7_cpusets/" class="article-date">
	   updated: <time datetime="2021-03-12T16:00:00.000Z" itemprop="dateUpdated">2021-03-13</time>
	</a>


        
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/Kernel-3-10-0-957-el7-%E5%86%85%E6%A0%B8%E6%96%87%E6%A1%A3/">Kernel_3.10.0-957.el7_内核文档</a>
  </span>

        

        
	<span class="article-read hidden-xs">
	    <i class="icon icon-eye-fill"></i>
	    <!--<span id="busuanzi_container_page_pv" style="display:inline;">-->
			<span id="busuanzi_value_page_pv" style="display:inline;"></span>
		<!--</span>-->
	</span>



        <!--<span class="post-comment"><i class="icon icon-comment"></i> <a href="/2021/03/13/Kernel-3.10.0-957.el7_cpusets/#comments" class="article-comment-link">评论</a></span> -->
        
	
	

      </div>
    </div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <pre><code>            CPUSETS
            -------
</code></pre>
<p>Copyright (C) 2004 BULL SA.<br>Written by <a href="mailto:&#x53;&#105;&#x6d;&#111;&#110;&#x2e;&#68;&#x65;&#x72;&#x72;&#64;&#98;&#x75;&#x6c;&#108;&#x2e;&#110;&#101;&#x74;">&#x53;&#105;&#x6d;&#111;&#110;&#x2e;&#68;&#x65;&#x72;&#x72;&#64;&#98;&#x75;&#x6c;&#108;&#x2e;&#110;&#101;&#x74;</a></p>
<p>Portions Copyright (c) 2004-2006 Silicon Graphics, Inc.<br>Modified by Paul Jackson <a href="mailto:&#112;&#x6a;&#x40;&#x73;&#x67;&#105;&#46;&#x63;&#111;&#109;">&#112;&#x6a;&#x40;&#x73;&#x67;&#105;&#46;&#x63;&#111;&#109;</a><br>Modified by Christoph Lameter <a href="mailto:&#99;&#x6c;&#97;&#x6d;&#101;&#116;&#x65;&#x72;&#64;&#x73;&#x67;&#105;&#x2e;&#x63;&#111;&#x6d;">&#99;&#x6c;&#97;&#x6d;&#101;&#116;&#x65;&#x72;&#64;&#x73;&#x67;&#105;&#x2e;&#x63;&#111;&#x6d;</a><br>Modified by Paul Menage <a href="mailto:&#109;&#x65;&#110;&#97;&#x67;&#x65;&#64;&#103;&#x6f;&#111;&#103;&#108;&#x65;&#x2e;&#x63;&#x6f;&#109;">&#109;&#x65;&#110;&#97;&#x67;&#x65;&#64;&#103;&#x6f;&#111;&#103;&#108;&#x65;&#x2e;&#x63;&#x6f;&#109;</a><br>Modified by Hidetoshi Seto <a href="mailto:&#115;&#x65;&#116;&#111;&#46;&#104;&#105;&#x64;&#x65;&#116;&#111;&#115;&#x68;&#x69;&#x40;&#106;&#x70;&#46;&#102;&#117;&#106;&#x69;&#116;&#x73;&#117;&#x2e;&#x63;&#111;&#x6d;">&#115;&#x65;&#116;&#111;&#46;&#104;&#105;&#x64;&#x65;&#116;&#111;&#115;&#x68;&#x69;&#x40;&#106;&#x70;&#46;&#102;&#117;&#106;&#x69;&#116;&#x73;&#117;&#x2e;&#x63;&#111;&#x6d;</a></p>
<h1 id="CONTENTS"><a href="#CONTENTS" class="headerlink" title="CONTENTS:"></a>CONTENTS:</h1><ol>
<li><p>Cpusets</p>
</li>
<li><p>1 What are cpusets ?</p>
</li>
<li><p>2 Why are cpusets needed ?</p>
</li>
<li><p>3 How are cpusets implemented ?</p>
</li>
<li><p>4 What are exclusive cpusets ?</p>
</li>
<li><p>5 What is memory_pressure ?</p>
</li>
<li><p>6 What is memory spread ?</p>
</li>
<li><p>7 What is sched_load_balance ?</p>
</li>
<li><p>8 What is sched_relax_domain_level ?</p>
</li>
<li><p>9 How do I use cpusets ?</p>
</li>
<li><p>Usage Examples and Syntax</p>
</li>
<li><p>1 Basic Usage</p>
</li>
<li><p>2 Adding/removing cpus</p>
</li>
<li><p>3 Setting flags</p>
</li>
<li><p>4 Attaching processes</p>
</li>
<li><p>Questions</p>
</li>
<li><p>Contact</p>
</li>
<li><h1 id="Cpusets"><a href="#Cpusets" class="headerlink" title="Cpusets"></a>Cpusets</h1></li>
</ol>
<h2 id="1-1-What-are-cpusets"><a href="#1-1-What-are-cpusets" class="headerlink" title="1.1 What are cpusets ?"></a>1.1 What are cpusets ?</h2><p>Cpusets provide a mechanism for assigning a set of CPUs and Memory<br>Nodes to a set of tasks.   In this document “Memory Node” refers to<br>an on-line node that contains memory.</p>
<p>Cpusets constrain the CPU and Memory placement of tasks to only<br>the resources within a task’s current cpuset.  They form a nested<br>hierarchy visible in a virtual file system.  These are the essential<br>hooks, beyond what is already present, required to manage dynamic<br>job placement on large systems.</p>
<p>Cpusets use the generic cgroup subsystem described in<br>Documentation/cgroups/cgroups.txt.</p>
<p>Requests by a task, using the sched_setaffinity(2) system call to<br>include CPUs in its CPU affinity mask, and using the mbind(2) and<br>set_mempolicy(2) system calls to include Memory Nodes in its memory<br>policy, are both filtered through that task’s cpuset, filtering out any<br>CPUs or Memory Nodes not in that cpuset.  The scheduler will not<br>schedule a task on a CPU that is not allowed in its cpus_allowed<br>vector, and the kernel page allocator will not allocate a page on a<br>node that is not allowed in the requesting task’s mems_allowed vector.</p>
<p>User level code may create and destroy cpusets by name in the cgroup<br>virtual file system, manage the attributes and permissions of these<br>cpusets and which CPUs and Memory Nodes are assigned to each cpuset,<br>specify and query to which cpuset a task is assigned, and list the<br>task pids assigned to a cpuset.</p>
<h2 id="1-2-Why-are-cpusets-needed"><a href="#1-2-Why-are-cpusets-needed" class="headerlink" title="1.2 Why are cpusets needed ?"></a>1.2 Why are cpusets needed ?</h2><p>The management of large computer systems, with many processors (CPUs),<br>complex memory cache hierarchies and multiple Memory Nodes having<br>non-uniform access times (NUMA) presents additional challenges for<br>the efficient scheduling and memory placement of processes.</p>
<p>Frequently more modest sized systems can be operated with adequate<br>efficiency just by letting the operating system automatically share<br>the available CPU and Memory resources amongst the requesting tasks.</p>
<p>But larger systems, which benefit more from careful processor and<br>memory placement to reduce memory access times and contention,<br>and which typically represent a larger investment for the customer,<br>can benefit from explicitly placing jobs on properly sized subsets of<br>the system.</p>
<p>This can be especially valuable on:</p>
<pre><code>* Web Servers running multiple instances of the same web application,
* Servers running different applications (for instance, a web server
  and a database), or
* NUMA systems running large HPC applications with demanding
  performance characteristics.
</code></pre>
<p>These subsets, or “soft partitions” must be able to be dynamically<br>adjusted, as the job mix changes, without impacting other concurrently<br>executing jobs. The location of the running jobs pages may also be moved<br>when the memory locations are changed.</p>
<p>The kernel cpuset patch provides the minimum essential kernel<br>mechanisms required to efficiently implement such subsets.  It<br>leverages existing CPU and Memory Placement facilities in the Linux<br>kernel to avoid any additional impact on the critical scheduler or<br>memory allocator code.</p>
<h2 id="1-3-How-are-cpusets-implemented"><a href="#1-3-How-are-cpusets-implemented" class="headerlink" title="1.3 How are cpusets implemented ?"></a>1.3 How are cpusets implemented ?</h2><p>Cpusets provide a Linux kernel mechanism to constrain which CPUs and<br>Memory Nodes are used by a process or set of processes.</p>
<p>The Linux kernel already has a pair of mechanisms to specify on which<br>CPUs a task may be scheduled (sched_setaffinity) and on which Memory<br>Nodes it may obtain memory (mbind, set_mempolicy).</p>
<p>Cpusets extends these two mechanisms as follows:</p>
<ul>
<li>Cpusets are sets of allowed CPUs and Memory Nodes, known to the<br>kernel.</li>
<li>Each task in the system is attached to a cpuset, via a pointer<br>in the task structure to a reference counted cgroup structure.</li>
<li>Calls to sched_setaffinity are filtered to just those CPUs<br>allowed in that task’s cpuset.</li>
<li>Calls to mbind and set_mempolicy are filtered to just<br>those Memory Nodes allowed in that task’s cpuset.</li>
<li>The root cpuset contains all the systems CPUs and Memory<br>Nodes.</li>
<li>For any cpuset, one can define child cpusets containing a subset<br>of the parents CPU and Memory Node resources.</li>
<li>The hierarchy of cpusets can be mounted at /dev/cpuset, for<br>browsing and manipulation from user space.</li>
<li>A cpuset may be marked exclusive, which ensures that no other<br>cpuset (except direct ancestors and descendants) may contain<br>any overlapping CPUs or Memory Nodes.</li>
<li>You can list all the tasks (by pid) attached to any cpuset.</li>
</ul>
<p>The implementation of cpusets requires a few, simple hooks<br>into the rest of the kernel, none in performance critical paths:</p>
<ul>
<li>in init/main.c, to initialize the root cpuset at system boot.</li>
<li>in fork and exit, to attach and detach a task from its cpuset.</li>
<li>in sched_setaffinity, to mask the requested CPUs by what’s<br>allowed in that task’s cpuset.</li>
<li>in sched.c migrate_live_tasks(), to keep migrating tasks within<br>the CPUs allowed by their cpuset, if possible.</li>
<li>in the mbind and set_mempolicy system calls, to mask the requested<br>Memory Nodes by what’s allowed in that task’s cpuset.</li>
<li>in page_alloc.c, to restrict memory to allowed nodes.</li>
<li>in vmscan.c, to restrict page recovery to the current cpuset.</li>
</ul>
<p>You should mount the “cgroup” filesystem type in order to enable<br>browsing and modifying the cpusets presently known to the kernel.  No<br>new system calls are added for cpusets - all support for querying and<br>modifying cpusets is via this cpuset file system.</p>
<p>The /proc/<pid>/status file for each task has four added lines,<br>displaying the task’s cpus_allowed (on which CPUs it may be scheduled)<br>and mems_allowed (on which Memory Nodes it may obtain memory),<br>in the two formats seen in the following example:</p>
<p>  Cpus_allowed:   ffffffff,ffffffff,ffffffff,ffffffff<br>  Cpus_allowed_list:      0-127<br>  Mems_allowed:   ffffffff,ffffffff<br>  Mems_allowed_list:      0-63</p>
<p>Each cpuset is represented by a directory in the cgroup file system<br>containing (on top of the standard cgroup files) the following<br>files describing that cpuset:</p>
<ul>
<li>cpuset.cpus: list of CPUs in that cpuset</li>
<li>cpuset.mems: list of Memory Nodes in that cpuset</li>
<li>cpuset.memory_migrate flag: if set, move pages to cpusets nodes</li>
<li>cpuset.cpu_exclusive flag: is cpu placement exclusive?</li>
<li>cpuset.mem_exclusive flag: is memory placement exclusive?</li>
<li>cpuset.mem_hardwall flag:  is memory allocation hardwalled</li>
<li>cpuset.memory_pressure: measure of how much paging pressure in cpuset</li>
<li>cpuset.memory_spread_page flag: if set, spread page cache evenly on allowed nodes</li>
<li>cpuset.memory_spread_slab flag: if set, spread slab cache evenly on allowed nodes</li>
<li>cpuset.sched_load_balance flag: if set, load balance within CPUs on that cpuset</li>
<li>cpuset.sched_relax_domain_level: the searching range when migrating tasks</li>
</ul>
<p>In addition, only the root cpuset has the following file:</p>
<ul>
<li>cpuset.memory_pressure_enabled flag: compute memory_pressure?</li>
</ul>
<p>New cpusets are created using the mkdir system call or shell<br>command.  The properties of a cpuset, such as its flags, allowed<br>CPUs and Memory Nodes, and attached tasks, are modified by writing<br>to the appropriate file in that cpusets directory, as listed above.</p>
<p>The named hierarchical structure of nested cpusets allows partitioning<br>a large system into nested, dynamically changeable, “soft-partitions”.</p>
<p>The attachment of each task, automatically inherited at fork by any<br>children of that task, to a cpuset allows organizing the work load<br>on a system into related sets of tasks such that each set is constrained<br>to using the CPUs and Memory Nodes of a particular cpuset.  A task<br>may be re-attached to any other cpuset, if allowed by the permissions<br>on the necessary cpuset file system directories.</p>
<p>Such management of a system “in the large” integrates smoothly with<br>the detailed placement done on individual tasks and memory regions<br>using the sched_setaffinity, mbind and set_mempolicy system calls.</p>
<p>The following rules apply to each cpuset:</p>
<ul>
<li>Its CPUs and Memory Nodes must be a subset of its parents.</li>
<li>It can’t be marked exclusive unless its parent is.</li>
<li>If its cpu or memory is exclusive, they may not overlap any sibling.</li>
</ul>
<p>These rules, and the natural hierarchy of cpusets, enable efficient<br>enforcement of the exclusive guarantee, without having to scan all<br>cpusets every time any of them change to ensure nothing overlaps a<br>exclusive cpuset.  Also, the use of a Linux virtual file system (vfs)<br>to represent the cpuset hierarchy provides for a familiar permission<br>and name space for cpusets, with a minimum of additional kernel code.</p>
<p>The cpus and mems files in the root (top_cpuset) cpuset are<br>read-only.  The cpus file automatically tracks the value of<br>cpu_online_mask using a CPU hotplug notifier, and the mems file<br>automatically tracks the value of node_states[N_MEMORY]–i.e.,<br>nodes with memory–using the cpuset_track_online_nodes() hook.</p>
<h2 id="1-4-What-are-exclusive-cpusets"><a href="#1-4-What-are-exclusive-cpusets" class="headerlink" title="1.4 What are exclusive cpusets ?"></a>1.4 What are exclusive cpusets ?</h2><p>If a cpuset is cpu or mem exclusive, no other cpuset, other than<br>a direct ancestor or descendant, may share any of the same CPUs or<br>Memory Nodes.</p>
<p>A cpuset that is cpuset.mem_exclusive <em>or</em> cpuset.mem_hardwall is “hardwalled”,<br>i.e. it restricts kernel allocations for page, buffer and other data<br>commonly shared by the kernel across multiple users.  All cpusets,<br>whether hardwalled or not, restrict allocations of memory for user<br>space.  This enables configuring a system so that several independent<br>jobs can share common kernel data, such as file system pages, while<br>isolating each job’s user allocation in its own cpuset.  To do this,<br>construct a large mem_exclusive cpuset to hold all the jobs, and<br>construct child, non-mem_exclusive cpusets for each individual job.<br>Only a small amount of typical kernel memory, such as requests from<br>interrupt handlers, is allowed to be taken outside even a<br>mem_exclusive cpuset.</p>
<h2 id="1-5-What-is-memory-pressure"><a href="#1-5-What-is-memory-pressure" class="headerlink" title="1.5 What is memory_pressure ?"></a>1.5 What is memory_pressure ?</h2><p>The memory_pressure of a cpuset provides a simple per-cpuset metric<br>of the rate that the tasks in a cpuset are attempting to free up in<br>use memory on the nodes of the cpuset to satisfy additional memory<br>requests.</p>
<p>This enables batch managers monitoring jobs running in dedicated<br>cpusets to efficiently detect what level of memory pressure that job<br>is causing.</p>
<p>This is useful both on tightly managed systems running a wide mix of<br>submitted jobs, which may choose to terminate or re-prioritize jobs that<br>are trying to use more memory than allowed on the nodes assigned to them,<br>and with tightly coupled, long running, massively parallel scientific<br>computing jobs that will dramatically fail to meet required performance<br>goals if they start to use more memory than allowed to them.</p>
<p>This mechanism provides a very economical way for the batch manager<br>to monitor a cpuset for signs of memory pressure.  It’s up to the<br>batch manager or other user code to decide what to do about it and<br>take action.</p>
<p>==&gt; Unless this feature is enabled by writing “1” to the special file<br>    /dev/cpuset/memory_pressure_enabled, the hook in the rebalance<br>    code of __alloc_pages() for this metric reduces to simply noticing<br>    that the cpuset_memory_pressure_enabled flag is zero.  So only<br>    systems that enable this feature will compute the metric.</p>
<p>Why a per-cpuset, running average:</p>
<pre><code>Because this meter is per-cpuset, rather than per-task or mm,
the system load imposed by a batch scheduler monitoring this
metric is sharply reduced on large systems, because a scan of
the tasklist can be avoided on each set of queries.

Because this meter is a running average, instead of an accumulating
counter, a batch scheduler can detect memory pressure with a
single read, instead of having to read and accumulate results
for a period of time.

Because this meter is per-cpuset rather than per-task or mm,
the batch scheduler can obtain the key information, memory
pressure in a cpuset, with a single read, rather than having to
query and accumulate results over all the (dynamically changing)
set of tasks in the cpuset.
</code></pre>
<p>A per-cpuset simple digital filter (requires a spinlock and 3 words<br>of data per-cpuset) is kept, and updated by any task attached to that<br>cpuset, if it enters the synchronous (direct) page reclaim code.</p>
<p>A per-cpuset file provides an integer number representing the recent<br>(half-life of 10 seconds) rate of direct page reclaims caused by<br>the tasks in the cpuset, in units of reclaims attempted per second,<br>times 1000.</p>
<h2 id="1-6-What-is-memory-spread"><a href="#1-6-What-is-memory-spread" class="headerlink" title="1.6 What is memory spread ?"></a>1.6 What is memory spread ?</h2><p>There are two boolean flag files per cpuset that control where the<br>kernel allocates pages for the file system buffers and related in<br>kernel data structures.  They are called ‘cpuset.memory_spread_page’ and<br>‘cpuset.memory_spread_slab’.</p>
<p>If the per-cpuset boolean flag file ‘cpuset.memory_spread_page’ is set, then<br>the kernel will spread the file system buffers (page cache) evenly<br>over all the nodes that the faulting task is allowed to use, instead<br>of preferring to put those pages on the node where the task is running.</p>
<p>If the per-cpuset boolean flag file ‘cpuset.memory_spread_slab’ is set,<br>then the kernel will spread some file system related slab caches,<br>such as for inodes and dentries evenly over all the nodes that the<br>faulting task is allowed to use, instead of preferring to put those<br>pages on the node where the task is running.</p>
<p>The setting of these flags does not affect anonymous data segment or<br>stack segment pages of a task.</p>
<p>By default, both kinds of memory spreading are off, and memory<br>pages are allocated on the node local to where the task is running,<br>except perhaps as modified by the task’s NUMA mempolicy or cpuset<br>configuration, so long as sufficient free memory pages are available.</p>
<p>When new cpusets are created, they inherit the memory spread settings<br>of their parent.</p>
<p>Setting memory spreading causes allocations for the affected page<br>or slab caches to ignore the task’s NUMA mempolicy and be spread<br>instead.    Tasks using mbind() or set_mempolicy() calls to set NUMA<br>mempolicies will not notice any change in these calls as a result of<br>their containing task’s memory spread settings.  If memory spreading<br>is turned off, then the currently specified NUMA mempolicy once again<br>applies to memory page allocations.</p>
<p>Both ‘cpuset.memory_spread_page’ and ‘cpuset.memory_spread_slab’ are boolean flag<br>files.  By default they contain “0”, meaning that the feature is off<br>for that cpuset.  If a “1” is written to that file, then that turns<br>the named feature on.</p>
<p>The implementation is simple.</p>
<p>Setting the flag ‘cpuset.memory_spread_page’ turns on a per-process flag<br>PFA_SPREAD_PAGE for each task that is in that cpuset or subsequently<br>joins that cpuset.  The page allocation calls for the page cache<br>is modified to perform an inline check for this PFA_SPREAD_PAGE task<br>flag, and if set, a call to a new routine cpuset_mem_spread_node()<br>returns the node to prefer for the allocation.</p>
<p>Similarly, setting ‘cpuset.memory_spread_slab’ turns on the flag<br>PFA_SPREAD_SLAB, and appropriately marked slab caches will allocate<br>pages from the node returned by cpuset_mem_spread_node().</p>
<p>The cpuset_mem_spread_node() routine is also simple.  It uses the<br>value of a per-task rotor cpuset_mem_spread_rotor to select the next<br>node in the current task’s mems_allowed to prefer for the allocation.</p>
<p>This memory placement policy is also known (in other contexts) as<br>round-robin or interleave.</p>
<p>This policy can provide substantial improvements for jobs that need<br>to place thread local data on the corresponding node, but that need<br>to access large file system data sets that need to be spread across<br>the several nodes in the jobs cpuset in order to fit.  Without this<br>policy, especially for jobs that might have one thread reading in the<br>data set, the memory allocation across the nodes in the jobs cpuset<br>can become very uneven.</p>
<h2 id="1-7-What-is-sched-load-balance"><a href="#1-7-What-is-sched-load-balance" class="headerlink" title="1.7 What is sched_load_balance ?"></a>1.7 What is sched_load_balance ?</h2><p>The kernel scheduler (kernel/sched.c) automatically load balances<br>tasks.  If one CPU is underutilized, kernel code running on that<br>CPU will look for tasks on other more overloaded CPUs and move those<br>tasks to itself, within the constraints of such placement mechanisms<br>as cpusets and sched_setaffinity.</p>
<p>The algorithmic cost of load balancing and its impact on key shared<br>kernel data structures such as the task list increases more than<br>linearly with the number of CPUs being balanced.  So the scheduler<br>has support to partition the systems CPUs into a number of sched<br>domains such that it only load balances within each sched domain.<br>Each sched domain covers some subset of the CPUs in the system;<br>no two sched domains overlap; some CPUs might not be in any sched<br>domain and hence won’t be load balanced.</p>
<p>Put simply, it costs less to balance between two smaller sched domains<br>than one big one, but doing so means that overloads in one of the<br>two domains won’t be load balanced to the other one.</p>
<p>By default, there is one sched domain covering all CPUs, including those<br>marked isolated using the kernel boot time “isolcpus=” argument. However,<br>the isolated CPUs will not participate in load balancing, and will not<br>have tasks running on them unless explicitly assigned.</p>
<p>This default load balancing across all CPUs is not well suited for<br>the following two situations:</p>
<ol>
<li>On large systems, load balancing across many CPUs is expensive.<br>If the system is managed using cpusets to place independent jobs<br>on separate sets of CPUs, full load balancing is unnecessary.</li>
<li>Systems supporting realtime on some CPUs need to minimize<br>system overhead on those CPUs, including avoiding task load<br>balancing if that is not needed.</li>
</ol>
<p>When the per-cpuset flag “cpuset.sched_load_balance” is enabled (the default<br>setting), it requests that all the CPUs in that cpusets allowed ‘cpuset.cpus’<br>be contained in a single sched domain, ensuring that load balancing<br>can move a task (not otherwised pinned, as by sched_setaffinity)<br>from any CPU in that cpuset to any other.</p>
<p>When the per-cpuset flag “cpuset.sched_load_balance” is disabled, then the<br>scheduler will avoid load balancing across the CPUs in that cpuset,<br>–except– in so far as is necessary because some overlapping cpuset<br>has “sched_load_balance” enabled.</p>
<p>So, for example, if the top cpuset has the flag “cpuset.sched_load_balance”<br>enabled, then the scheduler will have one sched domain covering all<br>CPUs, and the setting of the “cpuset.sched_load_balance” flag in any other<br>cpusets won’t matter, as we’re already fully load balancing.</p>
<p>Therefore in the above two situations, the top cpuset flag<br>“cpuset.sched_load_balance” should be disabled, and only some of the smaller,<br>child cpusets have this flag enabled.</p>
<p>When doing this, you don’t usually want to leave any unpinned tasks in<br>the top cpuset that might use non-trivial amounts of CPU, as such tasks<br>may be artificially constrained to some subset of CPUs, depending on<br>the particulars of this flag setting in descendant cpusets.  Even if<br>such a task could use spare CPU cycles in some other CPUs, the kernel<br>scheduler might not consider the possibility of load balancing that<br>task to that underused CPU.</p>
<p>Of course, tasks pinned to a particular CPU can be left in a cpuset<br>that disables “cpuset.sched_load_balance” as those tasks aren’t going anywhere<br>else anyway.</p>
<p>There is an impedance mismatch here, between cpusets and sched domains.<br>Cpusets are hierarchical and nest.  Sched domains are flat; they don’t<br>overlap and each CPU is in at most one sched domain.</p>
<p>It is necessary for sched domains to be flat because load balancing<br>across partially overlapping sets of CPUs would risk unstable dynamics<br>that would be beyond our understanding.  So if each of two partially<br>overlapping cpusets enables the flag ‘cpuset.sched_load_balance’, then we<br>form a single sched domain that is a superset of both.  We won’t move<br>a task to a CPU outside it cpuset, but the scheduler load balancing<br>code might waste some compute cycles considering that possibility.</p>
<p>This mismatch is why there is not a simple one-to-one relation<br>between which cpusets have the flag “cpuset.sched_load_balance” enabled,<br>and the sched domain configuration.  If a cpuset enables the flag, it<br>will get balancing across all its CPUs, but if it disables the flag,<br>it will only be assured of no load balancing if no other overlapping<br>cpuset enables the flag.</p>
<p>If two cpusets have partially overlapping ‘cpuset.cpus’ allowed, and only<br>one of them has this flag enabled, then the other may find its<br>tasks only partially load balanced, just on the overlapping CPUs.<br>This is just the general case of the top_cpuset example given a few<br>paragraphs above.  In the general case, as in the top cpuset case,<br>don’t leave tasks that might use non-trivial amounts of CPU in<br>such partially load balanced cpusets, as they may be artificially<br>constrained to some subset of the CPUs allowed to them, for lack of<br>load balancing to the other CPUs.</p>
<p>CPUs in “cpuset.isolcpus” were excluded from load balancing by the<br>isolcpus= kernel boot option, and will never be load balanced regardless<br>of the value of “cpuset.sched_load_balance” in any cpuset.</p>
<h2 id="1-7-1-sched-load-balance-implementation-details"><a href="#1-7-1-sched-load-balance-implementation-details" class="headerlink" title="1.7.1 sched_load_balance implementation details."></a>1.7.1 sched_load_balance implementation details.</h2><p>The per-cpuset flag ‘cpuset.sched_load_balance’ defaults to enabled (contrary<br>to most cpuset flags.)  When enabled for a cpuset, the kernel will<br>ensure that it can load balance across all the CPUs in that cpuset<br>(makes sure that all the CPUs in the cpus_allowed of that cpuset are<br>in the same sched domain.)</p>
<p>If two overlapping cpusets both have ‘cpuset.sched_load_balance’ enabled,<br>then they will be (must be) both in the same sched domain.</p>
<p>If, as is the default, the top cpuset has ‘cpuset.sched_load_balance’ enabled,<br>then by the above that means there is a single sched domain covering<br>the whole system, regardless of any other cpuset settings.</p>
<p>The kernel commits to user space that it will avoid load balancing<br>where it can.  It will pick as fine a granularity partition of sched<br>domains as it can while still providing load balancing for any set<br>of CPUs allowed to a cpuset having ‘cpuset.sched_load_balance’ enabled.</p>
<p>The internal kernel cpuset to scheduler interface passes from the<br>cpuset code to the scheduler code a partition of the load balanced<br>CPUs in the system. This partition is a set of subsets (represented<br>as an array of struct cpumask) of CPUs, pairwise disjoint, that cover<br>all the CPUs that must be load balanced.</p>
<p>The cpuset code builds a new such partition and passes it to the<br>scheduler sched domain setup code, to have the sched domains rebuilt<br>as necessary, whenever:</p>
<ul>
<li>the ‘cpuset.sched_load_balance’ flag of a cpuset with non-empty CPUs changes,</li>
<li>or CPUs come or go from a cpuset with this flag enabled,</li>
<li>or ‘cpuset.sched_relax_domain_level’ value of a cpuset with non-empty CPUs<br>and with this flag enabled changes,</li>
<li>or a cpuset with non-empty CPUs and with this flag enabled is removed,</li>
<li>or a cpu is offlined/onlined.</li>
</ul>
<p>This partition exactly defines what sched domains the scheduler should<br>setup - one sched domain for each element (struct cpumask) in the<br>partition.</p>
<p>The scheduler remembers the currently active sched domain partitions.<br>When the scheduler routine partition_sched_domains() is invoked from<br>the cpuset code to update these sched domains, it compares the new<br>partition requested with the current, and updates its sched domains,<br>removing the old and adding the new, for each change.</p>
<h2 id="1-8-What-is-sched-relax-domain-level"><a href="#1-8-What-is-sched-relax-domain-level" class="headerlink" title="1.8 What is sched_relax_domain_level ?"></a>1.8 What is sched_relax_domain_level ?</h2><p>In sched domain, the scheduler migrates tasks in 2 ways; periodic load<br>balance on tick, and at time of some schedule events.</p>
<p>When a task is woken up, scheduler try to move the task on idle CPU.<br>For example, if a task A running on CPU X activates another task B<br>on the same CPU X, and if CPU Y is X’s sibling and performing idle,<br>then scheduler migrate task B to CPU Y so that task B can start on<br>CPU Y without waiting task A on CPU X.</p>
<p>And if a CPU run out of tasks in its runqueue, the CPU try to pull<br>extra tasks from other busy CPUs to help them before it is going to<br>be idle.</p>
<p>Of course it takes some searching cost to find movable tasks and/or<br>idle CPUs, the scheduler might not search all CPUs in the domain<br>every time.  In fact, in some architectures, the searching ranges on<br>events are limited in the same socket or node where the CPU locates,<br>while the load balance on tick searches all.</p>
<p>For example, assume CPU Z is relatively far from CPU X.  Even if CPU Z<br>is idle while CPU X and the siblings are busy, scheduler can’t migrate<br>woken task B from X to Z since it is out of its searching range.<br>As the result, task B on CPU X need to wait task A or wait load balance<br>on the next tick.  For some applications in special situation, waiting<br>1 tick may be too long.</p>
<p>The ‘cpuset.sched_relax_domain_level’ file allows you to request changing<br>this searching range as you like.  This file takes int value which<br>indicates size of searching range in levels ideally as follows,<br>otherwise initial value -1 that indicates the cpuset has no request.</p>
<p>  -1  : no request. use system default or follow request of others.<br>   0  : no search.<br>   1  : search siblings (hyperthreads in a core).<br>   2  : search cores in a package.<br>   3  : search cpus in a node [= system wide on non-NUMA system]<br> ( 4  : search nodes in a chunk of node [on NUMA system] )<br> ( 5  : search system wide [on NUMA system] )</p>
<p>The system default is architecture dependent.  The system default<br>can be changed using the relax_domain_level= boot parameter.</p>
<p>This file is per-cpuset and affect the sched domain where the cpuset<br>belongs to.  Therefore if the flag ‘cpuset.sched_load_balance’ of a cpuset<br>is disabled, then ‘cpuset.sched_relax_domain_level’ have no effect since<br>there is no sched domain belonging the cpuset.</p>
<p>If multiple cpusets are overlapping and hence they form a single sched<br>domain, the largest value among those is used.  Be careful, if one<br>requests 0 and others are -1 then 0 is used.</p>
<p>Note that modifying this file will have both good and bad effects,<br>and whether it is acceptable or not depends on your situation.<br>Don’t modify this file if you are not sure.</p>
<p>If your situation is:</p>
<ul>
<li>The migration costs between each cpu can be assumed considerably<br>small(for you) due to your special application’s behavior or<br>special hardware support for CPU cache etc.</li>
<li>The searching cost doesn’t have impact(for you) or you can make<br>the searching cost enough small by managing cpuset to compact etc.</li>
<li>The latency is required even it sacrifices cache hit rate etc.<br>then increasing ‘sched_relax_domain_level’ would benefit you.</li>
</ul>
<h2 id="1-9-How-do-I-use-cpusets"><a href="#1-9-How-do-I-use-cpusets" class="headerlink" title="1.9 How do I use cpusets ?"></a>1.9 How do I use cpusets ?</h2><p>In order to minimize the impact of cpusets on critical kernel<br>code, such as the scheduler, and due to the fact that the kernel<br>does not support one task updating the memory placement of another<br>task directly, the impact on a task of changing its cpuset CPU<br>or Memory Node placement, or of changing to which cpuset a task<br>is attached, is subtle.</p>
<p>If a cpuset has its Memory Nodes modified, then for each task attached<br>to that cpuset, the next time that the kernel attempts to allocate<br>a page of memory for that task, the kernel will notice the change<br>in the task’s cpuset, and update its per-task memory placement to<br>remain within the new cpusets memory placement.  If the task was using<br>mempolicy MPOL_BIND, and the nodes to which it was bound overlap with<br>its new cpuset, then the task will continue to use whatever subset<br>of MPOL_BIND nodes are still allowed in the new cpuset.  If the task<br>was using MPOL_BIND and now none of its MPOL_BIND nodes are allowed<br>in the new cpuset, then the task will be essentially treated as if it<br>was MPOL_BIND bound to the new cpuset (even though its NUMA placement,<br>as queried by get_mempolicy(), doesn’t change).  If a task is moved<br>from one cpuset to another, then the kernel will adjust the task’s<br>memory placement, as above, the next time that the kernel attempts<br>to allocate a page of memory for that task.</p>
<p>If a cpuset has its ‘cpuset.cpus’ modified, then each task in that cpuset<br>will have its allowed CPU placement changed immediately.  Similarly,<br>if a task’s pid is written to another cpusets ‘cpuset.tasks’ file, then its<br>allowed CPU placement is changed immediately.  If such a task had been<br>bound to some subset of its cpuset using the sched_setaffinity() call,<br>the task will be allowed to run on any CPU allowed in its new cpuset,<br>negating the effect of the prior sched_setaffinity() call.</p>
<p>In summary, the memory placement of a task whose cpuset is changed is<br>updated by the kernel, on the next allocation of a page for that task,<br>and the processor placement is updated immediately.</p>
<p>Normally, once a page is allocated (given a physical page<br>of main memory) then that page stays on whatever node it<br>was allocated, so long as it remains allocated, even if the<br>cpusets memory placement policy ‘cpuset.mems’ subsequently changes.<br>If the cpuset flag file ‘cpuset.memory_migrate’ is set true, then when<br>tasks are attached to that cpuset, any pages that task had<br>allocated to it on nodes in its previous cpuset are migrated<br>to the task’s new cpuset. The relative placement of the page within<br>the cpuset is preserved during these migration operations if possible.<br>For example if the page was on the second valid node of the prior cpuset<br>then the page will be placed on the second valid node of the new cpuset.</p>
<p>Also if ‘cpuset.memory_migrate’ is set true, then if that cpuset’s<br>‘cpuset.mems’ file is modified, pages allocated to tasks in that<br>cpuset, that were on nodes in the previous setting of ‘cpuset.mems’,<br>will be moved to nodes in the new setting of ‘mems.’<br>Pages that were not in the task’s prior cpuset, or in the cpuset’s<br>prior ‘cpuset.mems’ setting, will not be moved.</p>
<p>There is an exception to the above.  If hotplug functionality is used<br>to remove all the CPUs that are currently assigned to a cpuset,<br>then all the tasks in that cpuset will be moved to the nearest ancestor<br>with non-empty cpus.  But the moving of some (or all) tasks might fail if<br>cpuset is bound with another cgroup subsystem which has some restrictions<br>on task attaching.  In this failing case, those tasks will stay<br>in the original cpuset, and the kernel will automatically update<br>their cpus_allowed to allow all online CPUs.  When memory hotplug<br>functionality for removing Memory Nodes is available, a similar exception<br>is expected to apply there as well.  In general, the kernel prefers to<br>violate cpuset placement, over starving a task that has had all<br>its allowed CPUs or Memory Nodes taken offline.</p>
<p>There is a second exception to the above.  GFP_ATOMIC requests are<br>kernel internal allocations that must be satisfied, immediately.<br>The kernel may drop some request, in rare cases even panic, if a<br>GFP_ATOMIC alloc fails.  If the request cannot be satisfied within<br>the current task’s cpuset, then we relax the cpuset, and look for<br>memory anywhere we can find it.  It’s better to violate the cpuset<br>than stress the kernel.</p>
<p>To start a new job that is to be contained within a cpuset, the steps are:</p>
<ol>
<li>mkdir /sys/fs/cgroup/cpuset</li>
<li>mount -t cgroup -ocpuset cpuset /sys/fs/cgroup/cpuset</li>
<li>Create the new cpuset by doing mkdir’s and write’s (or echo’s) in<br>the /sys/fs/cgroup/cpuset virtual file system.</li>
<li>Start a task that will be the “founding father” of the new job.</li>
<li>Attach that task to the new cpuset by writing its pid to the<br>/sys/fs/cgroup/cpuset tasks file for that cpuset.</li>
<li>fork, exec or clone the job tasks from this founding father task.</li>
</ol>
<p>For example, the following sequence of commands will setup a cpuset<br>named “Charlie”, containing just CPUs 2 and 3, and Memory Node 1,<br>and then start a subshell ‘sh’ in that cpuset:</p>
<p>  mount -t cgroup -ocpuset cpuset /sys/fs/cgroup/cpuset<br>  cd /sys/fs/cgroup/cpuset<br>  mkdir Charlie<br>  cd Charlie<br>  /bin/echo 2-3 &gt; cpuset.cpus<br>  /bin/echo 1 &gt; cpuset.mems<br>  /bin/echo $$ &gt; tasks<br>  sh</p>
<h1 id="The-subshell-‘sh’-is-now-running-in-cpuset-Charlie"><a href="#The-subshell-‘sh’-is-now-running-in-cpuset-Charlie" class="headerlink" title="The subshell ‘sh’ is now running in cpuset Charlie"></a>The subshell ‘sh’ is now running in cpuset Charlie</h1><h1 id="The-next-line-should-display-‘-Charlie’"><a href="#The-next-line-should-display-‘-Charlie’" class="headerlink" title="The next line should display ‘/Charlie’"></a>The next line should display ‘/Charlie’</h1><p>  cat /proc/self/cpuset</p>
<p>There are ways to query or modify cpusets:</p>
<ul>
<li>via the cpuset file system directly, using the various cd, mkdir, echo,<br>cat, rmdir commands from the shell, or their equivalent from C.</li>
<li>via the C library libcpuset.</li>
<li>via the C library libcgroup.<br>(<a target="_blank" rel="noopener" href="http://sourceforge.net/projects/libcg/">http://sourceforge.net/projects/libcg/</a>)</li>
<li>via the python application cset.<br>(<a target="_blank" rel="noopener" href="http://code.google.com/p/cpuset/">http://code.google.com/p/cpuset/</a>)</li>
</ul>
<p>The sched_setaffinity calls can also be done at the shell prompt using<br>SGI’s runon or Robert Love’s taskset.  The mbind and set_mempolicy<br>calls can be done at the shell prompt using the numactl command<br>(part of Andi Kleen’s numa package).</p>
<ol start="2">
<li><h1 id="Usage-Examples-and-Syntax"><a href="#Usage-Examples-and-Syntax" class="headerlink" title="Usage Examples and Syntax"></a>Usage Examples and Syntax</h1></li>
</ol>
<h2 id="2-1-Basic-Usage"><a href="#2-1-Basic-Usage" class="headerlink" title="2.1 Basic Usage"></a>2.1 Basic Usage</h2><p>Creating, modifying, using the cpusets can be done through the cpuset<br>virtual filesystem.</p>
<p>To mount it, type:</p>
<h1 id="mount-t-cgroup-o-cpuset-cpuset-sys-fs-cgroup-cpuset"><a href="#mount-t-cgroup-o-cpuset-cpuset-sys-fs-cgroup-cpuset" class="headerlink" title="mount -t cgroup -o cpuset cpuset /sys/fs/cgroup/cpuset"></a>mount -t cgroup -o cpuset cpuset /sys/fs/cgroup/cpuset</h1><p>Then under /sys/fs/cgroup/cpuset you can find a tree that corresponds to the<br>tree of the cpusets in the system. For instance, /sys/fs/cgroup/cpuset<br>is the cpuset that holds the whole system.</p>
<p>If you want to create a new cpuset under /sys/fs/cgroup/cpuset:</p>
<h1 id="cd-sys-fs-cgroup-cpuset"><a href="#cd-sys-fs-cgroup-cpuset" class="headerlink" title="cd /sys/fs/cgroup/cpuset"></a>cd /sys/fs/cgroup/cpuset</h1><h1 id="mkdir-my-cpuset"><a href="#mkdir-my-cpuset" class="headerlink" title="mkdir my_cpuset"></a>mkdir my_cpuset</h1><p>Now you want to do something with this cpuset.</p>
<h1 id="cd-my-cpuset"><a href="#cd-my-cpuset" class="headerlink" title="cd my_cpuset"></a>cd my_cpuset</h1><p>In this directory you can find several files:</p>
<h1 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h1><p>cgroup.clone_children  cpuset.memory_pressure<br>cgroup.event_control   cpuset.memory_spread_page<br>cgroup.procs           cpuset.memory_spread_slab<br>cpuset.cpu_exclusive   cpuset.mems<br>cpuset.cpus            cpuset.sched_load_balance<br>cpuset.mem_exclusive   cpuset.sched_relax_domain_level<br>cpuset.mem_hardwall    notify_on_release<br>cpuset.memory_migrate  tasks</p>
<p>Reading them will give you information about the state of this cpuset:<br>the CPUs and Memory Nodes it can use, the processes that are using<br>it, its properties.  By writing to these files you can manipulate<br>the cpuset.</p>
<p>Set some flags:</p>
<h1 id="bin-echo-1-gt-cpuset-cpu-exclusive"><a href="#bin-echo-1-gt-cpuset-cpu-exclusive" class="headerlink" title="/bin/echo 1 &gt; cpuset.cpu_exclusive"></a>/bin/echo 1 &gt; cpuset.cpu_exclusive</h1><p>Add some cpus:</p>
<h1 id="bin-echo-0-7-gt-cpuset-cpus"><a href="#bin-echo-0-7-gt-cpuset-cpus" class="headerlink" title="/bin/echo 0-7 &gt; cpuset.cpus"></a>/bin/echo 0-7 &gt; cpuset.cpus</h1><p>Add some mems:</p>
<h1 id="bin-echo-0-7-gt-cpuset-mems"><a href="#bin-echo-0-7-gt-cpuset-mems" class="headerlink" title="/bin/echo 0-7 &gt; cpuset.mems"></a>/bin/echo 0-7 &gt; cpuset.mems</h1><p>Now attach your shell to this cpuset:</p>
<h1 id="bin-echo-gt-tasks"><a href="#bin-echo-gt-tasks" class="headerlink" title="/bin/echo $$ &gt; tasks"></a>/bin/echo $$ &gt; tasks</h1><p>You can also create cpusets inside your cpuset by using mkdir in this<br>directory.</p>
<h1 id="mkdir-my-sub-cs"><a href="#mkdir-my-sub-cs" class="headerlink" title="mkdir my_sub_cs"></a>mkdir my_sub_cs</h1><p>To remove a cpuset, just use rmdir:</p>
<h1 id="rmdir-my-sub-cs"><a href="#rmdir-my-sub-cs" class="headerlink" title="rmdir my_sub_cs"></a>rmdir my_sub_cs</h1><p>This will fail if the cpuset is in use (has cpusets inside, or has<br>processes attached).</p>
<p>Note that for legacy reasons, the “cpuset” filesystem exists as a<br>wrapper around the cgroup filesystem.</p>
<p>The command</p>
<p>mount -t cpuset X /sys/fs/cgroup/cpuset</p>
<p>is equivalent to</p>
<p>mount -t cgroup -ocpuset,noprefix X /sys/fs/cgroup/cpuset<br>echo “/sbin/cpuset_release_agent” &gt; /sys/fs/cgroup/cpuset/release_agent</p>
<h2 id="2-2-Adding-removing-cpus"><a href="#2-2-Adding-removing-cpus" class="headerlink" title="2.2 Adding/removing cpus"></a>2.2 Adding/removing cpus</h2><p>This is the syntax to use when writing in the cpus or mems files<br>in cpuset directories:</p>
<h1 id="bin-echo-1-4-gt-cpuset-cpus-gt-set-cpus-list-to-cpus-1-2-3-4"><a href="#bin-echo-1-4-gt-cpuset-cpus-gt-set-cpus-list-to-cpus-1-2-3-4" class="headerlink" title="/bin/echo 1-4 &gt; cpuset.cpus        -&gt; set cpus list to cpus 1,2,3,4"></a>/bin/echo 1-4 &gt; cpuset.cpus        -&gt; set cpus list to cpus 1,2,3,4</h1><h1 id="bin-echo-1-2-3-4-gt-cpuset-cpus-gt-set-cpus-list-to-cpus-1-2-3-4"><a href="#bin-echo-1-2-3-4-gt-cpuset-cpus-gt-set-cpus-list-to-cpus-1-2-3-4" class="headerlink" title="/bin/echo 1,2,3,4 &gt; cpuset.cpus    -&gt; set cpus list to cpus 1,2,3,4"></a>/bin/echo 1,2,3,4 &gt; cpuset.cpus    -&gt; set cpus list to cpus 1,2,3,4</h1><p>To add a CPU to a cpuset, write the new list of CPUs including the<br>CPU to be added. To add 6 to the above cpuset:</p>
<h1 id="bin-echo-1-4-6-gt-cpuset-cpus-gt-set-cpus-list-to-cpus-1-2-3-4-6"><a href="#bin-echo-1-4-6-gt-cpuset-cpus-gt-set-cpus-list-to-cpus-1-2-3-4-6" class="headerlink" title="/bin/echo 1-4,6 &gt; cpuset.cpus    -&gt; set cpus list to cpus 1,2,3,4,6"></a>/bin/echo 1-4,6 &gt; cpuset.cpus    -&gt; set cpus list to cpus 1,2,3,4,6</h1><p>Similarly to remove a CPU from a cpuset, write the new list of CPUs<br>without the CPU to be removed.</p>
<p>To remove all the CPUs:</p>
<h1 id="bin-echo-“”-gt-cpuset-cpus-gt-clear-cpus-list"><a href="#bin-echo-“”-gt-cpuset-cpus-gt-clear-cpus-list" class="headerlink" title="/bin/echo “” &gt; cpuset.cpus        -&gt; clear cpus list"></a>/bin/echo “” &gt; cpuset.cpus        -&gt; clear cpus list</h1><h2 id="2-3-Setting-flags"><a href="#2-3-Setting-flags" class="headerlink" title="2.3 Setting flags"></a>2.3 Setting flags</h2><p>The syntax is very simple:</p>
<h1 id="bin-echo-1-gt-cpuset-cpu-exclusive-gt-set-flag-‘cpuset-cpu-exclusive’"><a href="#bin-echo-1-gt-cpuset-cpu-exclusive-gt-set-flag-‘cpuset-cpu-exclusive’" class="headerlink" title="/bin/echo 1 &gt; cpuset.cpu_exclusive     -&gt; set flag ‘cpuset.cpu_exclusive’"></a>/bin/echo 1 &gt; cpuset.cpu_exclusive     -&gt; set flag ‘cpuset.cpu_exclusive’</h1><h1 id="bin-echo-0-gt-cpuset-cpu-exclusive-gt-unset-flag-‘cpuset-cpu-exclusive’"><a href="#bin-echo-0-gt-cpuset-cpu-exclusive-gt-unset-flag-‘cpuset-cpu-exclusive’" class="headerlink" title="/bin/echo 0 &gt; cpuset.cpu_exclusive     -&gt; unset flag ‘cpuset.cpu_exclusive’"></a>/bin/echo 0 &gt; cpuset.cpu_exclusive     -&gt; unset flag ‘cpuset.cpu_exclusive’</h1><h2 id="2-4-Attaching-processes"><a href="#2-4-Attaching-processes" class="headerlink" title="2.4 Attaching processes"></a>2.4 Attaching processes</h2><h1 id="bin-echo-PID-gt-tasks"><a href="#bin-echo-PID-gt-tasks" class="headerlink" title="/bin/echo PID &gt; tasks"></a>/bin/echo PID &gt; tasks</h1><p>Note that it is PID, not PIDs. You can only attach ONE task at a time.<br>If you have several tasks to attach, you have to do it one after another:</p>
<h1 id="bin-echo-PID1-gt-tasks"><a href="#bin-echo-PID1-gt-tasks" class="headerlink" title="/bin/echo PID1 &gt; tasks"></a>/bin/echo PID1 &gt; tasks</h1><h1 id="bin-echo-PID2-gt-tasks"><a href="#bin-echo-PID2-gt-tasks" class="headerlink" title="/bin/echo PID2 &gt; tasks"></a>/bin/echo PID2 &gt; tasks</h1><pre><code>...
</code></pre>
<h1 id="bin-echo-PIDn-gt-tasks"><a href="#bin-echo-PIDn-gt-tasks" class="headerlink" title="/bin/echo PIDn &gt; tasks"></a>/bin/echo PIDn &gt; tasks</h1><ol start="3">
<li><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1></li>
</ol>
<p>Q: what’s up with this ‘/bin/echo’ ?<br>A: bash’s builtin ‘echo’ command does not check calls to write() against<br>   errors. If you use it in the cpuset file system, you won’t be<br>   able to tell whether a command succeeded or failed.</p>
<p>Q: When I attach processes, only the first of the line gets really attached !<br>A: We can only return one error code per call to write(). So you should also<br>   put only ONE pid.</p>
<ol start="4">
<li><h1 id="Contact"><a href="#Contact" class="headerlink" title="Contact"></a>Contact</h1></li>
</ol>
<p>Web: <a target="_blank" rel="noopener" href="http://www.bullopensource.org/cpuset">http://www.bullopensource.org/cpuset</a></p>

      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="http://www.oostech.com/2021/03/13/Kernel-3.10.0-957.el7_cpusets/" title="Kernel-3.10.0-957.el7_cpusets" target="_blank" rel="external">http://www.oostech.com/2021/03/13/Kernel-3.10.0-957.el7_cpusets/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.png" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="" target="_blank"><span class="text-dark">oosTech by Sam Lee</span><small class="ml-1x"></small></a></h3>
        <div></div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    

  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/2021/03/13/Kernel-3.10.0-957.el7_can/" title="Kernel-3.10.0-957.el7_can"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/2021/03/13/Kernel-3.10.0-957.el7_devices/" title="Kernel-3.10.0-957.el7_devices"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
    <li class="toggle-toc">
      <a class="toggle-btn collapsed" data-toggle="collapse" href="#collapseToc" aria-expanded="false" title="文章目录" role="button">
        <span>[&nbsp;</span><span>文章目录</span>
        <i class="text-collapsed icon icon-anchor"></i>
        <i class="text-in icon icon-close"></i>
        <span>]</span>
      </a>
    </li>
    
  </ul>
  
  
  <!-- Button trigger modal -->
  <button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>赏</span></button>
  <!-- <div class="wave-icon wave-icon-danger btn-donate" data-toggle="modal" data-target="#donateModal">
    <div class="wave-circle"><span class="icon"><i class="icon icon-bill"></i></span></div>
  </div> -->
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,wechat"></div>
    
  </div>
  </div>
    <div class="container" align="left">
    <div class="post-gallery" itemscope itemtype="http://schema.org/ImageGallery">
      <img src="/images/wechatp.png" itemprop="contentUrl">
      <span>欢迎关注公众号</span>
    </div>
    </div>
</nav>

  
<!-- Modal -->
<div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog">
  <div class="modal-dialog" role="document">
    <div class="modal-content donate">
      <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
      <div class="modal-body">
        <div class="donate-box">
          <div class="donate-head">
            <p>您能有收获就是我们最大的动力</p>
          </div>
          <div class="tab-content">
            <div role="tabpanel" class="tab-pane fade active in" id="alipay">
              <div class="donate-payimg">
                <img src="/images/donate/alipayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">不管多少都是对分享的肯定</p>
              <p class="text-grey">打开支付宝扫一扫，即可进行扫码捐赠</p>
            </div>
            <div role="tabpanel" class="tab-pane fade" id="wechatpay">
              <div class="donate-payimg">
                <img src="/images/donate/wechatpayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">不管多少都是对分享的肯定</p>
              <p class="text-grey">打开微信扫一扫，即可进行扫码捐赠</p>
            </div>
          </div>
          <div class="donate-footer">
            <ul class="nav nav-tabs nav-justified" role="tablist">
              <li role="presentation" class="active">
                <a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> 支付宝</a>
              </li>
              <li role="presentation" class="">
                <a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> 微信支付</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>




</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="http://google.com/" target="_blank" title="Google" data-toggle=tooltip data-placement=top><i class="icon icon-google"></i></a></li>
        
        <li><a href="https://twitter.com/" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
	<a target="_blank" rel="noopener" href="https://beian.miit.gov.cn" text-align: center >粤ICP备2021024811号</a>
        </div>
<!--    
    <div>
     <img src="/images/logo.png" width="140" height="140">
    </div>
-->
    </div>


        <!-- 不蒜子统计    //busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js -->
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        <!--<span id="busuanzi_container_site_pv" style="display:inline;">-->本站总访问量<span id="busuanzi_value_site_pv" style="display:inline;></span>次</span>
        <span class="post-meta-divider">|</span>
  
</footer>

  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>







   
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>











</body>
</html>